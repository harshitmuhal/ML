{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y1TzuyeXQeOW"
   },
   "source": [
    "## Linear Math -Vector, Matrix, Tensor, Matrix Product, Inverse Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DNOFpLKQQy22"
   },
   "source": [
    "### Basic library, function import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bal2U_bhQ8PC",
    "outputId": "e987cc1f-8b37-4413-9ef4-7c92a3426231"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ow6t2_QmRA9O"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def vector_plot(vecs, xlim, ylim, cols=[\"#1190FF\", \"#FF9A13\"], alpha=1):\n",
    "    plt.rc_context({'axes.edgecolor':'orange', 'xtick.color':'red', 'ytick.color':'red'})\n",
    "    plt.axvline(x=0, color='k', zorder=0)\n",
    "    plt.axhline(y=0, color='k', zorder=0)\n",
    "\n",
    "    for i in range(len(vecs)):\n",
    "        if (isinstance(alpha, list)):\n",
    "            alpha_i = alpha[i]\n",
    "        else:\n",
    "            alpha_i = alpha\n",
    "        x = np.concatenate([[0,0],vecs[i]])\n",
    "        plt.quiver([x[0]],\n",
    "                   [x[1]],\n",
    "                   [x[2]],\n",
    "                   [x[3]],\n",
    "                   angles='xy', scale_units='xy', scale=1, color=cols[i],\n",
    "                   alpha=alpha_i)\n",
    "        plt.ylim(-xlim, xlim)\n",
    "        plt.xlim(-ylim, ylim)\n",
    "        plt.grid()\n",
    "\n",
    "def plot_vector2d(vector2d, origin=[0, 0], **options):\n",
    "    return plt.arrow(origin[0], origin[1], vector2d[0], vector2d[1],\n",
    "                   head_width=0.2, head_length=0.3, length_includes_head=True,\n",
    "                   **options)\n",
    "\n",
    "def plot_transform(P_before, P_after, text_before, text_after, name, color=['#FF9A13', '#1190FF'], axis = [0, 5, 0, 4], arrows=False):\n",
    "    if arrows:\n",
    "        for vector_before, vector_after in zip(tf.transpose(P_before), tf.transpose(P_after)):\n",
    "            plot_vector2d(vector_before, color=\"#FF9A13\", linestyle=\"--\")\n",
    "            plot_vector2d(vector_after, color=\"#1190FF\", linestyle=\"-\")\n",
    "        plt.rc_context({'axes.edgecolor':'orange', 'xtick.color':'red', 'ytick.color':'red'})\n",
    "        plt.gca().add_artist(Polygon(tf.transpose(P_before), alpha=0.2))\n",
    "        plt.gca().add_artist(Polygon(tf.transpose(P_after), alpha=0.3, color=\"#FF9A13\"))\n",
    "        plt.text(-.25, 1, text_before, size=18, color=color[1])\n",
    "        plt.text(1.5, 0, text_after, size=18, color=color[0])\n",
    "        plt.title(name, color='w')\n",
    "        plt.axis(axis)\n",
    "        plt.grid()\n",
    "\n",
    "def evaluate(tensors):\n",
    "    \"\"\"Evaluates Tensor or EagerTensor to Numpy `ndarray`s.\n",
    "    Args:\n",
    "    tensors: Object of `Tensor` or EagerTensor`s; can be `list`, `tuple`,\n",
    "      `namedtuple` or combinations thereof.\n",
    "\n",
    "    Returns:\n",
    "      ndarrays: Object with same structure as `tensors` except with `Tensor` or\n",
    "        `EagerTensor`s replaced by Numpy `ndarray`s.\n",
    "    \"\"\"\n",
    "    return tf.nest.pack_sequence_as(tensors,[t.numpy() if tf.is_tensor(t) else t for t in tf.nest.flatten(tensors)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sfApd5HCfl-A"
   },
   "source": [
    "Linear Algebra is a field of mathematics that deals with linear equations, linear functions, and expressions through matrices and vector spaces.\n",
    "\n",
    "Machine learning relies heavily on linear algebra, it is important to understand vectors and matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "epJ6SETkaofP"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mkfhrJTrRM6Y"
   },
   "source": [
    "### 1-1. Scalars, Vectors, Matrices and Tensor\n",
    "- **Saclars**: Single number\n",
    "- **Vectors**: Array of numbers\n",
    "  - Numbers are sorted in order, and each number can be identified in order by index\n",
    "  - Vector is an arrow that can express a quantity with both size and direction (the direction of the arrow is the size, the direction is the direction)\n",
    "- **Matrices**: Matrix is a two-dimensional array of numbers, each element identified by two indices instead of one\n",
    "  - If matrix A has height m and width n, then  $A\\ in\\ \\mathbb {R}^{m \\times n}$\n",
    "  - The elements of the matrix $A_{m,n}$ \n",
    "\n",
    "![Scalars, Vectors, Matrices and Tensors](https://raw.githubusercontent.com/adhiraiyan/DeepLearningWithTF2.0/master/notebooks/figures/fig0201a.png)\n",
    "\n",
    "- **Tensor**: Array of numbers arranged in a regular grid with variable number of axes.A tensor is an array with more than 2 axis.\n",
    "  - $A_{i,j,k}$ :location $(i, j, k) $Tensor of $A$\n",
    "  - Vectors can be represented by three components: $(x, y, z)$\n",
    "\n",
    "![Tensors](https://raw.githubusercontent.com/adhiraiyan/DeepLearningWithTF2.0/master/notebooks/figures/fig0201b.PNG)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IAJzDOaBTgJp"
   },
   "source": [
    "$$\\color{Orange}{C=A+B\\ where\\ C_{i, j} = A_{i,j} + B_{i,j} \\tag{1}}$$\n",
    "- Tensor in Tensorflow\n",
    "  - Rank 0 Tensor: Scalar\n",
    "  - Rank 1 Tensor: Vector\n",
    "  - Rank 2 Tensor: Matrix\n",
    "  - Rank 3 Tensor: 3-Tensor\n",
    "  - Rank n Tensor: n-Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "d0RfWFwxe9rA",
    "outputId": "f2e1a4e9-f69e-4205-cb99-5f7d23fa34b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3x3 Rank 2 Tensor A: \n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]] \n",
      "\n",
      "3x3 Rank 2 Tensor B: \n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]] \n",
      "\n",
      "Rank 2 Tensor C with shape=(3, 3) and elements: \n",
      "[[ 2.  3.  4.]\n",
      " [ 5.  6.  7.]\n",
      " [ 8.  9. 10.]]\n"
     ]
    }
   ],
   "source": [
    "# ones 3x3 rank 2 tensor\n",
    "rank_2_tensor_A = tf.ones([3,3], name='MatrixA')\n",
    "print(\"3x3 Rank 2 Tensor A: \\n{} \\n\".format(rank_2_tensor_A))\n",
    "\n",
    "# 3x3 rank 2 tensor\n",
    "rank_2_tensor_B = tf.constant([[1,2,3], [4,5,6], [7,8,9]], name='MatrixB', dtype=tf.float32)\n",
    "print(\"3x3 Rank 2 Tensor B: \\n{} \\n\".format(rank_2_tensor_B))\n",
    "\n",
    "# add two tensor\n",
    "rank_2_tensor_C = tf.add(rank_2_tensor_A, rank_2_tensor_B, name='MatrixC')\n",
    "print(\"Rank 2 Tensor C with shape={} and elements: \\n{}\".format(rank_2_tensor_C.shape, rank_2_tensor_C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "4t5wjcF0gxO3",
    "outputId": "9ccc9bdc-7c49-413f-b323-3d95ac5c40fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2x3 Rank 2 Tensor two_by_three: \n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]] \n",
      "\n",
      "Imcompatible shapes to add with two_by_three of shape (2, 3)  and 3x3 Rank 2 Tensor B of shape(3, 3)\n"
     ]
    }
   ],
   "source": [
    "two_by_three = tf.ones([2,3])\n",
    "print(\"2x3 Rank 2 Tensor two_by_three: \\n{} \\n\".format(two_by_three))\n",
    "try:\n",
    "    incompatible_tensor = tf.add(two_by_three, rank_2_tensor_B)\n",
    "except:\n",
    "    print(\"Imcompatible shapes to add with two_by_three of shape {}\\\n",
    "    and 3x3 Rank 2 Tensor B of shape{}\".format(two_by_three.shape, rank_2_tensor_B.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-23BIA9HiedS"
   },
   "source": [
    "You can add a scalar to the matrix or multiply the matrix by a scalar by performing the corresponding operation on each element of the matrix.$$\\color{orange}{D=a \\cdot B+c\\ where\\ D_{i,j}=a \\cdot B_{i,j}+c \\tag{2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "sWL4m2gwCfU8",
    "outputId": "512d2fe5-0fc7-4af0-d338-257e5346820a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Rank 2 Tensor B: \n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]] \n",
      "\n",
      "Scalar a: 2.0 \n",
      "Rank 2 Tensor for aB: \n",
      "[[ 2.  4.  6.]\n",
      " [ 8. 10. 12.]\n",
      " [14. 16. 18.]] \n",
      "\n",
      "Scalar c: 3.0 \n",
      "Rank 2 Tensor D = aB+c: \n",
      "[[ 5.  7.  9.]\n",
      " [11. 13. 15.]\n",
      " [17. 19. 21.]] )\n"
     ]
    }
   ],
   "source": [
    "# scalar a,c and Matrix B\n",
    "rank_0_tensor_a = tf.constant(2, name=\"scalar_a\", dtype=tf.float32)\n",
    "rank_2_tensor_B = tf.constant([[1,2,3], [4,5,6], [7,8,9]], name=\"MatrixB\", dtype=tf.float32)\n",
    "rank_0_tensor_c = tf.constant(3, name=\"scalar_c\", dtype=tf.float32)\n",
    "\n",
    "# aB\n",
    "multiply_scalar = tf.multiply(rank_0_tensor_a, rank_2_tensor_B)\n",
    "\n",
    "# aB+c\n",
    "rank_2_tensor_D = tf.add(multiply_scalar, rank_0_tensor_c, name=\"MatrixD\")\n",
    "\n",
    "print(\"\"\"Original Rank 2 Tensor B: \\n{0} \\n\\nScalar a: {1} \\n\\\n",
    "Rank 2 Tensor for aB: \\n{2} \\n\\nScalar c: {3} \\n\\\n",
    "Rank 2 Tensor D = aB+c: \\n{4} )\"\"\".format(rank_2_tensor_B, rank_0_tensor_a, \n",
    "                                          multiply_scalar, rank_0_tensor_c, rank_2_tensor_D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g1PkE_1uC5W_"
   },
   "source": [
    "### Tanspose\n",
    "\n",
    " Transpose of a matrix is a matrix in which rows and columns are swapped along a diagonal line called the main diagonal.\n",
    "\n",
    "Change the $A$ matrix to $A\\ top$ and define as follows\n",
    "$$(A^\\top)_{i,j} = A_{j,i}$$\n",
    "\n",
    "In numpy there also exists Transpose of a tensor- It reverses the shape of the tensor.\n",
    "If shape was (x,y,z,d) then shape of transpose will be (d,z,y,x). However, you can also specify the axis as well in the transpose function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "yx-WgtDzQcHO",
    "outputId": "b3fa0282-1af6-4b06-e17e-ae57bfe6fc64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 2 Tensor E of shape: (2, 3) and elements: \n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "Tanspose of Rank 2 Tensor E of shape: (3, 2) and elements: \n",
      "[[1 4]\n",
      " [2 5]\n",
      " [3 6]]\n"
     ]
    }
   ],
   "source": [
    "# rank 2 Matrix E\n",
    "rank_2_tensor_E = tf.constant([[1,2,3], [4,5,6]])\n",
    "\n",
    "# transpose Matrix E\n",
    "transpose_E = tf.transpose(rank_2_tensor_E, name=\"transposeE\")\n",
    "\n",
    "print(\"\"\"Rank 2 Tensor E of shape: {0} and elements: \\n{1}\\n\\\n",
    "Tanspose of Rank 2 Tensor E of shape: {2} and elements: \\n{3}\"\"\".format(rank_2_tensor_E.shape, rank_2_tensor_E,\n",
    "                                                                        transpose_E.shape, transpose_E))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SNZhb-VfRh7J"
   },
   "source": [
    "### Broadcasting -\n",
    "broadcasting is not supported by python lists. It is supported by only numpy vectors/matrices/tensors.\n",
    "- Adding scalar to a vector adds that scalar to each element of vector\n",
    "- Adding vector to a matrix will add the vector to each row or to each column of matrix depending on the shape of vector\n",
    "\n",
    "In deep learning, another matrix with $C_{i,j} = A_{i,j}+b_j$ can be created by adding a matrix and a vector.\n",
    "That is, the vector b is added to each row of the matrix, and implicit copying of b to multiple locations is called **broadcasting**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "xID7ARgnUGFt",
    "outputId": "2a29f28e-6587-4596-bcfc-0490c851cf1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 2 tensor A: \n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      " \n",
      "Rank 1 Tensor b: \n",
      "[[4.]\n",
      " [5.]\n",
      " [6.]]\n",
      "Rank 2 tensor F = A+b: \n",
      "[[5. 5. 5.]\n",
      " [6. 6. 6.]\n",
      " [7. 7. 7.]]\n"
     ]
    }
   ],
   "source": [
    "# rank 1 vector b\n",
    "rank_1_tensor_b = tf.constant([[4.], [5.], [6.]])\n",
    "# broadcast, F = A + b\n",
    "rank_2_tensor_F = tf.add(rank_2_tensor_A, rank_1_tensor_b, name=\"broadcastF\")\n",
    "\n",
    "print(\"\"\"Rank 2 tensor A: \\n{0}\\n \\nRank 1 Tensor b: \\n{1}\\\n",
    "\\nRank 2 tensor F = A+b: \\n{2}\"\"\".format(rank_2_tensor_A, rank_1_tensor_b, rank_2_tensor_F))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EnK4-q-RU3bN"
   },
   "source": [
    "### 1-2. Multiplying Matrices and Vectors\n",
    "To define matrix product of matrices $A$, $B$, and $A$, $A$ must have the same number of columns as $B$\n",
    "\n",
    "If the shape of $A$ is $m\\times n$ and the shape of $B$ is $n \\times p$, then the shape of $C$ is $m \\times p$\n",
    "$$\\color{orange}{C_{i,j}=\\sum_kA_{i,k}B_{k,j} \\tag{3}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "C0D_m8uBYEbS",
    "outputId": "d6078aff-5469-4a24-b1b7-30b3b3a2480f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A: shape (2, 3) \n",
      "elements: \n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "\n",
      "Matrix B: shape (3, 4) \n",
      "elements: \n",
      "[[1. 2. 3. 4.]\n",
      " [1. 2. 3. 4.]\n",
      " [1. 2. 3. 4.]]\n",
      "Matrix C: shape (2, 4) \n",
      "elements: \n",
      "[[ 3.  6.  9. 12.]\n",
      " [ 3.  6.  9. 12.]]\n"
     ]
    }
   ],
   "source": [
    "# Matrix A shape: (2,3) B shape: (3,4)\n",
    "mmv_matrix_A = tf.ones([2,3], name=\"matrix_A\")\n",
    "mmv_matrix_B = tf.constant([[1,2,3,4], [1,2,3,4], [1,2,3,4]], name=\"matrix_B\", dtype=tf.float32)\n",
    "\n",
    "# Matrix C: C=AB, C shape: (2,4)\n",
    "matrix_multiply_C = tf.matmul(mmv_matrix_A, mmv_matrix_B, name=\"matrix_multiply_C\")\n",
    "\n",
    "print(\"\"\"Matrix A: shape {0} \\nelements: \\n{1}\\\n",
    "\\n\\nMatrix B: shape {2} \\nelements: \\n{3}\\\n",
    "\\nMatrix C: shape {4} \\nelements: \\n{5}\"\"\".format(mmv_matrix_A.shape, mmv_matrix_A,\n",
    "                                                  mmv_matrix_B.shape, mmv_matrix_B,\n",
    "                                                  matrix_multiply_C.shape, matrix_multiply_C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UdX3EGpmZNqi"
   },
   "source": [
    "To get a matrix containing the product of individual elements, use **element wise production** or **Handmamard product** and write $A \\odot B$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "aO5QPA0ta5ww",
    "outputId": "4b8778fd-216e-4eaa-be47-a441f17c1c34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A: shape (3, 3) \n",
      "elements: \n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "\n",
      "Matrix A: shape (3, 3) \n",
      "elements: \n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n",
      "Matrix C: shape (3, 3) \n",
      "elements: \n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n"
     ]
    }
   ],
   "source": [
    "# Matrix A, B shape (3,3)\n",
    "element_matrix_A = tf.ones([3,3], name=\"element_matrix_A\")\n",
    "element_matrix_B = tf.constant([[1,2,3], [4,5,6], [7,8,9]], name=\"element_matrix_B\", dtype=tf.float32)\n",
    "\n",
    "# element wise product\n",
    "element_wise_C = tf.multiply(element_matrix_A, element_matrix_B, name=\"element_wise_C\")\n",
    "\n",
    "print(\"\"\"Matrix A: shape {0} \\nelements: \\n{1}\\\n",
    "\\n\\nMatrix A: shape {2} \\nelements: \\n{3}\\\n",
    "\\nMatrix C: shape {4} \\nelements: \\n{5}\"\"\".format(element_matrix_A.shape, element_matrix_A,\n",
    "                                                  element_matrix_B.shape, element_matrix_B,\n",
    "                                                  element_wise_C.shape, element_wise_C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6EwvEXLUbbE_"
   },
   "source": [
    "![Dot Product](https://raw.githubusercontent.com/adhiraiyan/DeepLearningWithTF2.0/master/notebooks/figures/fig0202b.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "xrvxI5Vgco6n",
    "outputId": "7a1e924b-3ba5-4b69-839e-8bb78fed2ecb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A: shape (3, 3) \n",
      "elements: \n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "\n",
      "Matrix B: shape (3, 3) \n",
      "elements: \n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n",
      "Matrix C: shape (3, 3) \n",
      "elements: \n",
      "[[12. 15. 18.]\n",
      " [12. 15. 18.]\n",
      " [12. 15. 18.]]\n"
     ]
    }
   ],
   "source": [
    "# Matrix A, B shape: (3,3)\n",
    "dot_matrix_A = tf.ones([3,3], name=\"dot_matrix_A\")\n",
    "dot_matrix_B = tf.constant([[1,2,3], [4,5,6], [7,8,9]], name=\"dot_matrix_B\", dtype=tf.float32)\n",
    "\n",
    "# Dot Product AB\n",
    "dot_product_C = tf.tensordot(dot_matrix_A, dot_matrix_B, axes=1, name=\"dot_product_C\")\n",
    "\n",
    "print(\"\"\"Matrix A: shape {0} \\nelements: \\n{1}\\\n",
    "\\n\\nMatrix B: shape {2} \\nelements: \\n{3}\\n\\\n",
    "Matrix C: shape {4} \\nelements: \\n{5}\"\"\".format(dot_matrix_A.shape, dot_matrix_A,\n",
    "                                                dot_matrix_B.shape, dot_matrix_B,\n",
    "                                                dot_product_C.shape, dot_product_C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S9_OGpi1c8W8"
   },
   "source": [
    "\n",
    "Some properties of matrix multiplication (variance properties): $$\\color{orange}{A(B+C)=AB+AC\\tag{4}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EaPDxI0LfB7g"
   },
   "outputs": [],
   "source": [
    "matrix_A = tf.constant([[1,2], [3,4]], name=\"matrix_a\")\n",
    "matrix_B = tf.constant([[5,6], [7,8]], name=\"matrix_b\")\n",
    "matrix_C = tf.constant([[9,1], [2,3]], name=\"matrix_c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "mUUaWCtVfcG2",
    "outputId": "f6aafc6c-49df-41c9-8927-e765deaa92c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A: \n",
      "[[1 2]\n",
      " [3 4]] \n",
      "\n",
      "Matrix B: \n",
      "[[5 6]\n",
      " [7 8]] \n",
      "\n",
      "Matrix C: \n",
      "[[9 1]\n",
      " [2 3]]\n",
      "\n",
      "Distributive property is valid RHS: AB+AC: \n",
      "[[32 29]\n",
      " [78 65]] \n",
      "\n",
      "LHS: A(B+C): \n",
      "[[32 29]\n",
      " [78 65]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Matrix A: \\n{} \\n\\nMatrix B: \\n{} \\n\\nMatrix C: \\n{}\\n\".format(matrix_A, matrix_B, matrix_C))\n",
    "\n",
    "# AB+AC\n",
    "distributive_RHS = tf.add(tf.matmul(matrix_A, matrix_B), tf.matmul(matrix_A, matrix_C), name=\"RHS\")\n",
    "\n",
    "# A(B+C)\n",
    "distributive_LHS = tf.matmul(matrix_A, (tf.add(matrix_B, matrix_C)), name=\"LHS\")\n",
    "\n",
    "predictor = tf.reduce_all(tf.equal(distributive_RHS, distributive_LHS))\n",
    "\n",
    "def true_print():\n",
    "    print(\"\"\"Distributive property is valid RHS: AB+AC: \\n{} \\n\\nLHS: A(B+C): \\n{}\"\"\".format(distributive_RHS, distributive_LHS))\n",
    "\n",
    "def false_print():\n",
    "    print(\"\"\"You Broke the Distributive Property of Matrix RHS: AB+AC: \\n{}\\\n",
    "  \\n\\nis NOT Equal to LHS: A(B+C): \\n{}\"\"\".format(distributive_RHS, distributive_LHS))\n",
    "\n",
    "tf.cond(predictor, true_print, false_print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TctPeoMTh2J4"
   },
   "source": [
    "Some properties of matrix multiplication (association properties):\n",
    " $$\\color{orange}{A(BC)=(AB)C\\tag{5}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "17eV6P6si_Jv",
    "outputId": "7b76fc03-12db-48e8-c0ff-752c7c0c0eee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A: \n",
      "[[1 2]\n",
      " [3 4]] \n",
      "\n",
      "Matrix B: \n",
      "[[5 6]\n",
      " [7 8]] \n",
      "\n",
      "Matrix C: \n",
      "[[9 1]\n",
      " [2 3]]\n",
      "\n",
      "Assosiative property is valid RHS: (AB)C: \n",
      "[[215  85]\n",
      " [487 193]] \n",
      "\n",
      "LHS: A(BC): \n",
      "[[215  85]\n",
      " [487 193]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Matrix A: \\n{} \\n\\nMatrix B: \\n{} \\n\\nMatrix C: \\n{}\\n\".format(matrix_A, matrix_B, matrix_C))\n",
    "# (AB)C\n",
    "assosiative_RHS = tf.matmul(tf.matmul(matrix_A, matrix_B), matrix_C)\n",
    "# A(BC)\n",
    "assosiative_LHS = tf.matmul(matrix_A, tf.matmul(matrix_B, matrix_C))\n",
    "predictor = tf.reduce_all(tf.equal(assosiative_RHS, assosiative_LHS))\n",
    "def true_print():\n",
    "    print(\"\"\"Assosiative property is valid RHS: (AB)C: \\n{} \\n\\nLHS: A(BC): \\n{}\"\"\".format(assosiative_RHS, assosiative_LHS))\n",
    "def false_print():\n",
    "    print(\"\"\"You Broke the Assosiative Property of Matrix RHS: (AB)C): \\n{}\\\n",
    "  \\n\\nis NOT Equal to LHS: A(BC): \\n{}\"\"\".format(assosiative_RHS, assosiative_LHS))\n",
    "tf.cond(predictor, true_print, false_print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XSXLrPc1kdJ4"
   },
   "source": [
    "Some properties of matrix multiplication $$\\color{orange}{AB \\neq BA\\tag{6}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "ojpfGJyvli7c",
    "outputId": "c9d19d5a-4d5a-4897-dbf3-90b539c6dbc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A: \n",
      "[[1 2]\n",
      " [3 4]] \n",
      "\n",
      "Matrix B: \n",
      "[[5 6]\n",
      " [7 8]]\n",
      "Matrix Multiplication is not commutative  (AB): \n",
      "[[19 22]\n",
      " [43 50]] \n",
      "\n",
      "LHS: (BA): \n",
      "[[23 34]\n",
      " [31 46]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Matrix A: \\n{} \\n\\nMatrix B: \\n{}\".format(matrix_A, matrix_B))\n",
    "\n",
    "# Matrix A times B\n",
    "commutative_RHS = tf.matmul(matrix_A, matrix_B)\n",
    "\n",
    "# Matrix B times A\n",
    "commutative_LHS = tf.matmul(matrix_B, matrix_A)\n",
    "\n",
    "predictor = tf.logical_not(tf.reduce_all(tf.equal(commutative_RHS, commutative_LHS)))\n",
    "\n",
    "def true_print():\n",
    "    print(\"\"\"Matrix Multiplication is not commutative  (AB): \\n{} \\n\\nLHS: (BA): \\n{}\"\"\".format(commutative_RHS, commutative_LHS))\n",
    "\n",
    "def false_print():\n",
    "    print(\"\"\"You made Matrix Multipliccation commutative RHS: (AB): \\n{}\\\n",
    "  \\n\\n LHS: (BA): \\n{}\"\"\".format(commutative_RHS, commutative_LHS))\n",
    "\n",
    "tf.cond(predictor, true_print, false_print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wqh738hLmVk0"
   },
   "source": [
    "(Transpose): $$\\color{orange}{(AB)^\\top = B^\\top A^\\top\\tag{7}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "o3Zi1B6KpD-I",
    "outputId": "2a4f2486-661e-4160-f7fc-1600d2b4f5a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A: \n",
      "[[1 2]\n",
      " [3 4]] \n",
      "\n",
      "Matrix B: \n",
      "[[5 6]\n",
      " [7 8]]\n",
      "\n",
      "Transpose property is valid RHS: (AB)^T: \n",
      "[[19 43]\n",
      " [22 50]]  \n",
      "\n",
      "LHS: (B^T A^T): \n",
      "[[19 43]\n",
      " [22 50]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Matrix A: \\n{} \\n\\nMatrix B: \\n{}\\n\".format(matrix_A, matrix_B))\n",
    "\n",
    "transpose_RHS = tf.transpose(tf.matmul(matrix_A, matrix_B))\n",
    "\n",
    "transpose_LHS = tf.matmul(matrix_B, matrix_A, transpose_a=True, transpose_b=True)\n",
    "\n",
    "predictor = tf.reduce_all(tf.equal(transpose_RHS, transpose_LHS))\n",
    "\n",
    "def true_print():\n",
    "    print(\"\"\"Transpose property is valid RHS: (AB)^T: \\n{}\\\n",
    "  \\n\\nLHS: (B^T A^T): \\n{}\"\"\".format(transpose_RHS, transpose_LHS))\n",
    "\n",
    "def false_print():\n",
    "    print(\"\"\"You Broken the Transpose property of Matrix RHS: (AB)^T: \\n{}\\\n",
    "  \\n\\nLHS: (B^TA^T): \\n{}\"\"\".format(transpose_RHS, transpose_LHS))\n",
    "\n",
    "tf.cond(predictor, true_print, false_print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vvU9udD1rg5Y"
   },
   "source": [
    "### 1-3. Identity and Inverse Matrices\n",
    "Linear algebra provides a powerful tool called **matrix inversion**.\n",
    "Analytical resolution of $Ax=b$ for many values ​​of $A$\n",
    "To explain matrix inversion, we need to first define the concept of **identity matrix**.\n",
    "The identity matrix is ​​a matrix that does not change the vector when multiplied by that matrix.\n",
    "$$\\color{orange}{I_n \\in \\mathbb{R}^{n \\times m} \\text{and}\\ \\forall x \\in \\mathbb{R}^n, I_nx = x \\tag{8} }$$\n",
    "\n",
    "The structure of the identity matrix is ​​that all items along the main diagonal are 1 and all items are 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "Kiezd49DL4Ki",
    "outputId": "eb0f5ed6-6d7e-46c2-e1fe-76c4e8f1efe4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identity matrix I: \n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "\n",
      "Vector x: \n",
      "[[4.]\n",
      " [5.]\n",
      " [6.]]\n",
      "\n",
      "Matrix C from Ix: \n",
      "[[4.]\n",
      " [5.]\n",
      " [6.]]\n"
     ]
    }
   ],
   "source": [
    "# matrix I\n",
    "identity_matrix_I = tf.eye(3,3, dtype=tf.float32, name='IdentityMatrixI')\n",
    "print(\"Identity matrix I: \\n{}\\n\".format(identity_matrix_I))\n",
    "\n",
    "iim_vector_x = tf.constant([[4], [5], [6]], name='Vector_x', dtype=tf.float32)\n",
    "print(\"Vector x: \\n{}\\n\".format(iim_vector_x))\n",
    "\n",
    "iim_matrix_C = tf.matmul(identity_matrix_I, iim_vector_x, name='MatrixC')\n",
    "print(\"Matrix C from Ix: \\n{}\".format(iim_matrix_C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE1QPOo9QEeB"
   },
   "source": [
    "**Matrix inverse** of $A$ is expressed as $A^{-1}$ and is defined as follows\n",
    "$$\\color{orange}{A^{-1}A = I_n\\tag{9}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tlo8leChTn9V"
   },
   "source": [
    "\n",
    "The equation $Ax=b$ can be solved as\n",
    "$$\\color{orange}{A^{-1}Ax=A^{-1}b \\\\\n",
    "I_nx=A^{-1}b \\\\\n",
    "x=A^{-1}b\\tag{10}}$$\n",
    "\n",
    "![Matrix Inverse](https://raw.githubusercontent.com/adhiraiyan/DeepLearningWithTF2.0/master/notebooks/figures/fig0203a.PNG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "5FJ7V-eUb866",
    "outputId": "47d2706e-65d1-4303-9127-7f459d242ce1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A: \n",
      "[[2. 3.]\n",
      " [4. 9.]] \n",
      "\n",
      "Vector B: \n",
      "[[ 6.]\n",
      " [15.]]\n",
      "\n",
      "Vector x is: \n",
      "[[1.5]\n",
      " [1. ]] \n",
      "Where x = [1.5] and y = [1.]\n"
     ]
    }
   ],
   "source": [
    "sys_matrix_A = tf.constant([[2,3], [4,9]], dtype=tf.float32)\n",
    "sys_vector_B = tf.constant([[6], [15]], dtype=tf.float32)\n",
    "\n",
    "print(\"Matrix A: \\n{} \\n\\nVector B: \\n{}\\n\".format(sys_matrix_A, sys_vector_B))\n",
    "\n",
    "# x = A^(-1)b\n",
    "sys_x = tf.matmul(tf.linalg.inv(sys_matrix_A), sys_vector_B)\n",
    "print(\"Vector x is: \\n{} \\nWhere x = {} and y = {}\".format(sys_x, sys_x[0], sys_x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is a linear transformation ?\n",
    "\n",
    "To transform the vector space such that it preserves **certain properties** of the vector space structure.\n",
    "\n",
    "T : V $\\rightarrow$ W\n",
    "\n",
    "- $\\vec{0} \\rightarrow \\vec{0}$ ie. the null vector corresponding to vector space V should be mapped to the null vector in vector space W\n",
    "- The lines which are parallel in vector space V should remain parallel in the vector space W\n",
    "\n",
    "##### Geometric significance of linear transofmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOoZq3rZypIpcxzZaFQt5T7",
   "collapsed_sections": [],
   "name": "LinearAlgebra_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
